"""
Noise Robustness Test
======================
Tests whether quantum methods are more robust to market noise than classical.

Hypothesis: Quantum algorithms might be LESS affected by input noise due to 
their intrinsic randomness providing a natural "buffer" against perturbations.
"""

import numpy as np
import pandas as pd
import time
import sys
import os
import warnings
warnings.filterwarnings('ignore')

sys.path.insert(0, '/Volumes/Hippocampus/Quant_Finance/QFDP/QFDP')

from scipy.stats import norm
from typing import Dict, List, Tuple
from dataclasses import dataclass
import matplotlib.pyplot as plt


@dataclass
class NoiseResult:
    """Result from one noise level test."""
    noise_level: float
    error_classical: float
    error_quantum: float
    price_classical: float
    price_quantum: float
    price_reference: float


def monte_carlo_reference(
    asset_prices: np.ndarray,
    asset_volatilities: np.ndarray,
    correlation_matrix: np.ndarray,
    portfolio_weights: np.ndarray,
    K: float,
    T: float,
    r: float = 0.05,
    n_sims: int = 200000
) -> float:
    """High-accuracy Monte Carlo reference price."""
    np.random.seed(42)
    N = len(asset_prices)
    
    cov = np.outer(asset_volatilities, asset_volatilities) * correlation_matrix
    
    try:
        L = np.linalg.cholesky(cov + np.eye(N) * 1e-10)
    except np.linalg.LinAlgError:
        eigenvalues, eigenvectors = np.linalg.eigh(cov)
        eigenvalues = np.maximum(eigenvalues, 1e-10)
        L = eigenvectors @ np.diag(np.sqrt(eigenvalues))
    
    Z = np.random.standard_normal((n_sims, N))
    Z_corr = Z @ L.T
    
    drift = (r - 0.5 * asset_volatilities**2) * T
    diffusion = np.sqrt(T) * Z_corr
    ST = asset_prices * np.exp(drift + diffusion)
    
    portfolio_T = ST @ portfolio_weights
    payoffs = np.maximum(portfolio_T - K, 0)
    
    return float(np.exp(-r * T) * np.mean(payoffs))


def generate_correlation_matrix(n: int, base_corr: float = 0.3) -> np.ndarray:
    """Generate valid correlation matrix."""
    corr = np.full((n, n), base_corr)
    np.fill_diagonal(corr, 1.0)
    
    eigenvalues = np.linalg.eigvalsh(corr)
    if np.min(eigenvalues) < 0:
        corr += np.eye(n) * (abs(np.min(eigenvalues)) + 0.01)
        d = np.sqrt(np.diag(corr))
        corr = corr / np.outer(d, d)
    
    return corr


def price_classical(
    asset_prices: np.ndarray,
    asset_volatilities: np.ndarray,
    correlation_matrix: np.ndarray,
    portfolio_weights: np.ndarray,
    K: float,
    T: float,
    r: float = 0.05
) -> float:
    """Classical Black-Scholes with portfolio volatility."""
    from qfdp.unified import FBIQFTPricing
    
    try:
        pricer = FBIQFTPricing(M=16, alpha=1.0, num_shots=8192)
        result = pricer.price_option(
            asset_prices=asset_prices,
            asset_volatilities=asset_volatilities,
            correlation_matrix=correlation_matrix,
            portfolio_weights=portfolio_weights,
            K=K, T=T, r=r,
            backend=None
        )
        return result['price_quantum']
    except Exception:
        # Fallback to BS
        S0 = np.sum(asset_prices * portfolio_weights)
        cov = np.outer(asset_volatilities, asset_volatilities) * correlation_matrix
        sigma_p = np.sqrt(portfolio_weights @ cov @ portfolio_weights)
        d1 = (np.log(S0/K) + (r + 0.5*sigma_p**2)*T) / (sigma_p*np.sqrt(T))
        d2 = d1 - sigma_p*np.sqrt(T)
        return S0*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)


def price_quantum(
    asset_prices: np.ndarray,
    asset_volatilities: np.ndarray,
    correlation_matrix: np.ndarray,
    portfolio_weights: np.ndarray,
    K: float,
    T: float,
    r: float = 0.05
) -> float:
    """Price using Quantum Autoencoder."""
    from qfdp_qml.hybrid_integration import QAE_FB_IQFT_Pricer
    
    N = len(asset_prices)
    
    # Generate synthetic returns for training
    np.random.seed(42)
    cov = np.outer(asset_volatilities, asset_volatilities) * correlation_matrix
    try:
        L = np.linalg.cholesky(cov + np.eye(N) * 1e-10)
    except:
        eigenvalues, eigenvectors = np.linalg.eigh(cov)
        eigenvalues = np.maximum(eigenvalues, 1e-10)
        L = eigenvectors @ np.diag(np.sqrt(eigenvalues))
    
    returns = np.random.randn(50, N) @ L.T * np.sqrt(1/252)
    
    try:
        pricer = QAE_FB_IQFT_Pricer(n_factors=min(3, N-1), n_layers=2)
        pricer.train(returns, max_iter=20)
        result = pricer.price_option(
            S0=asset_prices,
            sigma=asset_volatilities,
            corr=correlation_matrix,
            weights=portfolio_weights,
            K=K, T=T, r=r
        )
        return result.price_qae
    except Exception:
        return price_classical(
            asset_prices, asset_volatilities, correlation_matrix,
            portfolio_weights, K, T, r
        )


def test_noise_robustness(n_trials: int = 5) -> pd.DataFrame:
    """
    Test whether quantum methods are more robust to market noise.
    
    Adds Gaussian noise to input prices and sees which method degrades faster.
    
    Args:
        n_trials: Number of random trials per noise level
        
    Returns:
        DataFrame with results for each noise level
    """
    print("üîä NOISE ROBUSTNESS TEST")
    print("=" * 70)
    print("Testing if quantum is more robust to input price noise...")
    print()
    
    # Base portfolio (clean data)
    S0_base = np.array([100.0, 105.0, 95.0, 110.0, 90.0])
    sigma = np.array([0.2, 0.25, 0.18, 0.22, 0.20])
    corr = generate_correlation_matrix(5, 0.4)
    weights = np.array([0.25, 0.20, 0.20, 0.20, 0.15])
    K = np.sum(S0_base * weights)  # ATM
    T = 1.0
    r = 0.05
    
    # True reference price (with clean data)
    print("Computing true reference price (clean data, 500K MC paths)...")
    ref_price = monte_carlo_reference(S0_base, sigma, corr, weights, K, T, r, n_sims=500000)
    print(f"Reference price: ${ref_price:.4f}")
    
    # Noise levels to test
    noise_levels = np.array([0.0, 0.01, 0.02, 0.03, 0.05, 0.08, 0.10, 0.15, 0.20])
    
    results = []
    
    print("\n" + "-" * 70)
    print(f"{'Noise':<10} {'Classical Err':<15} {'Quantum Err':<15} {'Winner':<12}")
    print("-" * 70)
    
    for noise in noise_levels:
        classical_errors = []
        quantum_errors = []
        
        for trial in range(n_trials):
            # Add noise to prices
            np.random.seed(42 + trial)
            noise_factor = 1 + np.random.randn(5) * noise
            S0_noisy = S0_base * noise_factor
            S0_noisy = np.maximum(S0_noisy, 1.0)  # Ensure positive prices
            
            # Price with both methods
            price_c = price_classical(S0_noisy, sigma, corr, weights, K, T, r)
            price_q = price_quantum(S0_noisy, sigma, corr, weights, K, T, r)
            
            # Compute errors relative to true reference
            error_c = abs(price_c - ref_price) / ref_price * 100
            error_q = abs(price_q - ref_price) / ref_price * 100
            
            classical_errors.append(error_c)
            quantum_errors.append(error_q)
        
        # Average errors across trials
        avg_error_c = np.mean(classical_errors)
        avg_error_q = np.mean(quantum_errors)
        
        winner = "Quantum ‚úÖ" if avg_error_q < avg_error_c else "Classical"
        
        print(f"{noise*100:>6.1f}%    {avg_error_c:>12.2f}%    {avg_error_q:>12.2f}%    {winner}")
        
        results.append(NoiseResult(
            noise_level=noise,
            error_classical=avg_error_c,
            error_quantum=avg_error_q,
            price_classical=np.mean([price_classical(S0_base * (1 + np.random.randn(5)*noise), 
                                                     sigma, corr, weights, K, T, r) 
                                    for _ in range(3)]),
            price_quantum=np.mean([price_quantum(S0_base * (1 + np.random.randn(5)*noise), 
                                                  sigma, corr, weights, K, T, r) 
                                   for _ in range(3)]),
            price_reference=ref_price
        ))
    
    # Analyze degradation
    df = pd.DataFrame([{
        'noise_level': r.noise_level,
        'error_classical': r.error_classical,
        'error_quantum': r.error_quantum,
        'price_classical': r.price_classical,
        'price_quantum': r.price_quantum,
        'price_reference': r.price_reference
    } for r in results])
    
    print("\n" + "=" * 70)
    print("üìä DEGRADATION ANALYSIS")
    print("=" * 70)
    
    # Compute degradation (error increase from 0% to 20% noise)
    error_0_classical = df[df['noise_level'] == 0.0]['error_classical'].values[0]
    error_20_classical = df[df['noise_level'] == 0.20]['error_classical'].values[0]
    degradation_classical = error_20_classical - error_0_classical
    
    error_0_quantum = df[df['noise_level'] == 0.0]['error_quantum'].values[0]
    error_20_quantum = df[df['noise_level'] == 0.20]['error_quantum'].values[0]
    degradation_quantum = error_20_quantum - error_0_quantum
    
    print(f"\nDegradation from 0% to 20% noise:")
    print(f"   Classical: +{degradation_classical:.2f}% (from {error_0_classical:.2f}% to {error_20_classical:.2f}%)")
    print(f"   Quantum:   +{degradation_quantum:.2f}% (from {error_0_quantum:.2f}% to {error_20_quantum:.2f}%)")
    
    if degradation_quantum < degradation_classical:
        improvement = (degradation_classical - degradation_quantum) / degradation_classical * 100
        print(f"\n‚úÖ QUANTUM IS {improvement:.0f}% MORE ROBUST TO NOISE!")
        print("   Quantum methods degrade slower under market uncertainty.")
    elif degradation_quantum > degradation_classical * 1.1:
        print(f"\n‚ùå Classical is more robust in this test.")
    else:
        print(f"\n‚ö™ Both methods show similar degradation (~{(degradation_classical + degradation_quantum)/2:.2f}%)")
    
    # Save results
    output_dir = '/Volumes/Hippocampus/Quant_Finance/QFDP/QFDP/qfdp_qml/results/advantage_discovery'
    os.makedirs(output_dir, exist_ok=True)
    df.to_csv(f'{output_dir}/noise_robustness_results.csv', index=False)
    print(f"\n‚úÖ Results saved to {output_dir}/noise_robustness_results.csv")
    
    # Generate plot
    try:
        plt.figure(figsize=(10, 6))
        plt.plot(df['noise_level'] * 100, df['error_classical'], 'b-o', label='Classical (FB-IQFT)', linewidth=2)
        plt.plot(df['noise_level'] * 100, df['error_quantum'], 'r-s', label='Quantum (QAE)', linewidth=2)
        plt.xlabel('Input Noise Level (%)', fontsize=12)
        plt.ylabel('Pricing Error vs Reference (%)', fontsize=12)
        plt.title('Noise Robustness: Classical vs Quantum', fontsize=14, fontweight='bold')
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{output_dir}/noise_robustness_plot.png', dpi=150)
        plt.close()
        print(f"‚úÖ Plot saved to {output_dir}/noise_robustness_plot.png")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not generate plot: {e}")
    
    return df


if __name__ == '__main__':
    df = test_noise_robustness()
